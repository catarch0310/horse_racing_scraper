import pandas as pd
from datetime import datetime
import os
import importlib
import google.generativeai as genai
import time
from difflib import SequenceMatcher

# --- 1. AI æ ¸å¿ƒè¨­å®šèˆ‡è‡ªå‹•åµæ¸¬ ---
API_KEY = os.getenv("GEMINI_API_KEY")

def get_best_model():
    """ è‡ªå‹•åµæ¸¬å¯ç”¨çš„æ¨¡å‹åç¨±ï¼Œè§£æ±º 404 v1beta éŒ¯èª¤ """
    if not API_KEY:
        return None
    genai.configure(api_key=API_KEY)
    candidate_names = [
        'gemini-1.5-flash', 
        'models/gemini-1.5-flash', 
        'gemini-1.5-pro',
        'models/gemini-1.5-pro'
    ]
    print("ğŸ¤– æ­£åœ¨åµæ¸¬å¯ç”¨ AI æ¨¡å‹...")
    for name in candidate_names:
        try:
            model = genai.GenerativeModel(name)
            model.generate_content("hi", generation_config={"max_output_tokens": 1})
            print(f"âœ… æˆåŠŸå•Ÿç”¨æ¨¡å‹: {name}")
            return model
        except Exception:
            continue
    return None

# åˆå§‹åŒ–æ¨¡å‹å¯¦ä¾‹
model_instance = get_best_model()

# --- 2. è³‡æ–™æ¸…æ´—å·¥å…·ï¼šæ¨™é¡Œç›¸ä¼¼åº¦æ¯”å° ---
def similarity(a, b):
    """ è¨ˆç®—å…©å€‹æ¨™é¡Œä¹‹é–“çš„ç›¸ä¼¼åº¦æ¯”ä¾‹ """
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()

def deduplicate_data(all_data):
    """ é€²è¡ŒåŸå§‹æ•¸æ“šæ¸…æ´—ï¼š1.ç¶²å€å»é‡ 2.æ¨™é¡Œæ¨¡ç³Šå»é‡ """
    if not all_data: return []
    
    print(f"\nğŸ§¹ é–‹å§‹è³‡æ–™æ¸…æ´— (åŸå§‹ç¸½æ•¸: {len(all_data)} å‰‡)...")
    
    # æ­¥é©Ÿ 1: ç¶²å€å”¯ä¸€åŒ– (URL De-duplication)
    unique_url_data = []
    seen_urls = set()
    for item in all_data:
        if item['link'] not in seen_urls:
            seen_urls.add(item['link'])
            unique_url_data.append(item)
    
    # æ­¥é©Ÿ 2: æ¨™é¡Œç›¸ä¼¼åº¦éæ¿¾ (Fuzzy Matching)
    final_data = []
    for item in unique_url_data:
        is_duplicate = False
        current_title = item['title']
        
        for existing_item in final_data:
            # å¦‚æœç›¸ä¼¼åº¦è¶…é 0.75ï¼Œè¦–ç‚ºé‡è¤‡å ±å°
            if similarity(current_title, existing_item['title']) > 0.75:
                is_duplicate = True
                break
        
        if not is_duplicate:
            final_data.append(item)
            
    print(f"âœ¨ æ¸…æ´—å®Œæˆ: æœ€çµ‚ä¿ç•™ {len(final_data)} å‰‡ç²¾è¯æ–°è (éæ¿¾æ‰ {len(all_data) - len(final_data)} å‰‡é‡è¤‡)")
    return final_data

# --- 3. AI å ±å‘Šç”Ÿæˆ ---
def generate_ai_report(cleaned_headlines):
    """ å°‡æ¸…æ´—éçš„æ¨™é¡ŒæŠ•çµ¦ AI é€²è¡Œåˆ†é¡ã€æ’åºèˆ‡ä¸‰èªæ‘˜è¦ """
    if not model_instance:
        return "AI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼šæ¨¡å‹æœªå°±ç·’ã€‚"

    # æ ¼å¼åŒ–æ–°èæ¸…å–®ä¾› AI é–±è®€
    news_list_text = ""
    for i, item in enumerate(cleaned_headlines):
        news_list_text += f"{i+1}. [{item['source']}] {item['title']}\n"

    prompt = f"""
    You are a professional Global Horse Racing Chief Editor. 
    Below is today's cleaned headlines from UK, HK, AU, JP, and US:
    
    {news_list_text}
    
    Please generate a comprehensive "Global Horse Racing Intelligence Report" in THREE languages in this exact order:
    1. ENGLISH VERSION
    2. TRADITIONAL CHINESE VERSION (HONG KONG)
    3. JAPANESE VERSION

    Each language section must include:
    - **Top 5 Priority News**: Select the 5 most critical stories globally and explain their significance in one sentence.
    - **Categorized Highlights**: Group remaining news into "HK & Asia Racing", "International Majors", "Bloodstock & Sales", and "Expert Analysis".
    - **Global Market Sentiment**: A 100-word summary of today's global racing trend.

    --- MANDATORY INSTRUCTIONS FOR CHINESE ---
    - Use Traditional Chinese (Hong Kong).
    - CRITICAL: Horse names, Trainers, Jockeys, and Race titles MUST follow official Hong Kong Jockey Club (HKJC) translations.
    - Examples: 'James McDonald' -> 'éº¥é“æœ—', 'David Hayes' -> 'å¸Œæ–¯', 'Classic Mile' -> 'é¦™æ¸¯ç¶“å…¸ä¸€å“©è³½', 'Caulfield' -> 'è€ƒè²çˆ¾å¾·'.

    --- MANDATORY INSTRUCTIONS FOR JAPANESE ---
    - Use professional Japanese racing terminology (e.g., é‡è³, è¿½ã„åˆ‡ã‚Š, ãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¦ãƒˆ).

    Format with professional Markdown headers.
    """

    try:
        # å¢åŠ  output tokens ç¢ºä¿å®Œæ•´ç”Ÿæˆä¸‰ç¨®èªè¨€
        response = model_instance.generate_content(
            prompt,
            generation_config={"max_output_tokens": 4000, "temperature": 0.7}
        )
        return response.text.strip()
    except Exception as e:
        return f"AI å ±å‘Šå…§å®¹ç”Ÿæˆå‡ºéŒ¯: {str(e)}"

# --- 4. ä¸»åŸ·è¡Œæµç¨‹ ---
def run_all():
    raw_collected_data = []
    # å®Œæ•´ 11 å€‹ç«™é»æ¸…å–®
    SITES = [
        'racing_post', 'scmp_racing', 'singtao_racing', 'punters_au', 
        'racing_com', 'tospo_keiba', 'netkeiba_news', 'bloodhorse_news', 
        'the_straight', 'anz_bloodstock', 'ttr_ausnz'
    ]
    
    # A. æŠ“å–éšæ®µ
    for site in SITES:
        try:
            print(f"\n>>> ä»»å‹™é–‹å§‹: {site}")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data: item['source'] = site
                raw_collected_data.extend(data)
                print(f"    âœ… æŠ“åˆ° {len(data)} å‰‡")
        except Exception as e:
            print(f"    âŒ {site} åŸ·è¡ŒéŒ¯èª¤: {e}")

    # B. è³‡æ–™æ¸…æ´— (å»é‡)
    cleaned_data = deduplicate_data(raw_collected_data)

    if cleaned_data:
        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('data', exist_ok=True)

        # C. è¼¸å‡ºæ–‡ä»¶ 1: æ¸…æ´—å¾Œçš„åŸå§‹æ•¸æ“š (CSV)
        df = pd.DataFrame(cleaned_data)
        csv_filename = f"data/global_news_{date_str}.csv"
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ åŸå§‹æ•¸æ“š (CSV) å·²å­˜è‡³: {csv_filename}")

        # D. è¼¸å‡ºæ–‡ä»¶ 2: AI ä¸‰èªå ±å‘Š (Markdown)
        print(f"\nğŸ¤– å•Ÿå‹• AI ç¸½ç·¨è¼¯æ¨¡å¼ï¼Œæ­£åœ¨åˆ†æå…¨çƒæƒ…å ±...")
        ai_report = generate_ai_report(cleaned_data)
        
        md_filename = f"data/racing_report_{date_str}.md"
        with open(md_filename, "w", encoding="utf-8") as f:
            f.write(ai_report)
        
        print(f"âœ¨ ä¸‰èª AI æˆ°æƒ…å ±å‘Šå·²å®Œæˆ: {md_filename}")
    else:
        print("\nâŒ ä»Šæ—¥æœªç™¼ç¾ç¬¦åˆæ™‚é–“æ¢ä»¶çš„æ–°èã€‚")

if __name__ == "__main__":
    run_all()
