import pandas as pd
from datetime import datetime
import os
import importlib
import google.generativeai as genai
import time

# --- AI è¨­å®šèˆ‡è‡ªå‹•åµæ¸¬ (å®Œå…¨ä¿ç•™ä½ çš„ç©©å®šé‚è¼¯) ---
API_KEY = os.getenv("GEMINI_API_KEY")

def get_best_model():
    if not API_KEY: return None
    genai.configure(api_key=API_KEY)
    candidate_names = ['gemini-1.5-flash', 'models/gemini-1.5-flash', 'gemini-1.5-pro', 'models/gemini-1.5-pro']
    print("ğŸ¤– æ­£åœ¨åµæ¸¬å¯ç”¨ AI æ¨¡å‹...")
    for name in candidate_names:
        try:
            model = genai.GenerativeModel(name)
            model.generate_content("hi", generation_config={"max_output_tokens": 1})
            print(f"âœ… æˆåŠŸå•Ÿç”¨æ¨¡å‹: {name}")
            return model
        except Exception: continue
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"âš ï¸ ä½¿ç”¨ç³»çµ±è‡ªå‹•ç™¼ç¾æ¨¡å‹: {m.name}")
                return genai.GenerativeModel(m.name)
    except: pass
    return None

model_instance = get_best_model()

# --- æ–°å¢åŠŸèƒ½ï¼šç©©å®šç‰ˆæ¨™é¡Œç¿»è­¯ ---
def translate_titles_to_en(all_data):
    """å°‡éè‹±æ–‡æ¨™é¡Œç¿»è­¯ä¸¦é™„åœ¨å¾Œé¢ï¼Œç¢ºä¿è³‡æ–™ä¸äº‚æ‰"""
    if not model_instance or not all_data: return all_data
    
    print(f"ğŸŒ æ­£åœ¨ç¿»è­¯ {len(all_data)} å‰‡æ¨™é¡Œ...")
    
    # æŠ½å–æ¨™é¡Œ
    raw_titles = [item['title'] for item in all_data]
    prompt = "Translate the following horse racing headlines into English. Reply with ONLY the English translations, one per line, no numbering, no extra text. If a line is already in English, keep it as is:\n\n" + "\n".join(raw_titles)

    try:
        response = model_instance.generate_content(prompt)
        translated_lines = response.text.strip().split('\n')
        
        # æ ¸å¿ƒæª¢æŸ¥ï¼šå¦‚æœ AI å›å‚³çš„è¡Œæ•¸è·ŸåŸå§‹æ¨™é¡Œä¸€è‡´ï¼Œæ‰é€²è¡Œåˆä½µ
        if len(translated_lines) == len(all_data):
            for i in range(len(all_data)):
                orig = all_data[i]['title']
                en = translated_lines[i].strip()
                # å¦‚æœç¿»è­¯çµæœèˆ‡åŸæ–‡æ˜é¡¯ä¸åŒï¼ˆå³åŸæ–‡æ˜¯ä¸­æ—¥æ–‡ï¼‰ï¼Œæ‰é™„åŠ 
                if orig.lower() != en.lower():
                    all_data[i]['title'] = f"{orig} ({en})"
            print("âœ… æ¨™é¡Œè‹±è­¯æˆåŠŸä¸¦å·²é™„åŠ ")
        else:
            print(f"âš ï¸ ç¿»è­¯è¡Œæ•¸ä¸ç¬¦ ({len(translated_lines)} vs {len(all_data)})ï¼Œç‚ºä¿å®‰å…¨æ”¾æ£„æœ¬æ¬¡ç¿»è­¯")
    except Exception as e:
        print(f"âš ï¸ ç¿»è­¯éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return all_data

def generate_ai_report(all_headlines):
    """ç”¢å‡ºä¸‰èªå°ˆæ¥­å ±å‘Š"""
    if not model_instance: return "AI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼šæ¨¡å‹åˆå§‹åŒ–å¤±æ•—ã€‚"

    news_list_text = ""
    for i, item in enumerate(all_headlines):
        news_list_text += f"{i+1}. [{item['source']}] {item['title']}\n"

    prompt = f"""
    You are a Global Horse Racing Chief Editor. Analyze these headlines from UK, HK, AU, JP, US, and FRANCE:
    
    {news_list_text}
    
    Please generate a report in THREE parts in this exact order:
    1. ENGLISH VERSION
    2. TRADITIONAL CHINESE VERSION (HONG KONG)
    3. JAPANESE VERSION

    Requirements for each language:
    - **Top 5 Priority**: Choose the 5 most important global news and explain why in one sentence.
    - **Categorized Summaries**: Summarize others into "HK Racing", "International Racing", and "Analysis".
    - **Global Trend**: A 100-word analysis of today's atmosphere.

    --- SPECIAL INSTRUCTIONS FOR CHINESE ---
    - Use Traditional Chinese (Hong Kong).
    - **MANDATORY**: Use official Hong Kong Jockey Club (HKJC) translations for names.
    - Examples: 'David Hayes' -> 'å¸Œæ–¯', 'Aidan O'Brien' -> 'å²³ä¼¯ä»', 'Sha Tin' -> 'æ²™ç”°', 'Happy Valley' -> 'è·‘é¦¬åœ°'.

    --- SPECIAL INSTRUCTIONS FOR JAPANESE ---
    - Use professional Japanese horse racing terminology (e.g., é‡è³, è¿½ã„åˆ‡ã‚Š).

    Format with professional Markdown headers.
    """
    try:
        # è¨­å®šè¼ƒé«˜çš„ max_output_tokens ä»¥å®¹ç´ä¸‰èª
        response = model_instance.generate_content(prompt, generation_config={"max_output_tokens": 5000})
        return response.text.strip()
    except Exception as e:
        return f"AI å ±å‘Šå…§å®¹ç”Ÿæˆå‡ºéŒ¯: {str(e)}"

def run_all():
    all_data = []
    SITES = ['racing_post', 'scmp_racing', 'singtao_racing', 'punters_au', 'racing_com', 'tospo_keiba', 'netkeiba_news', 'bloodhorse_news', 'the_straight', 'anz_bloodstock', 'ttr_ausnz', 'smh_racing', 'drf_news', 'racenet_news', 'daily_telegraph', 'equidia_racing']
    
    for site in SITES:
        try:
            print(f"\n>>> ä»»å‹™é–‹å§‹: {site}")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data: item['source'] = site
                all_data.extend(data)
                print(f"    âœ… æŠ“åˆ° {len(data)} å‰‡")
        except Exception as e:
            print(f"    âŒ {site} éŒ¯èª¤: {e}")

    if all_data:
        # åœ¨å­˜æª”èˆ‡å ±åå‰ï¼Œå…ˆé€²è¡Œç¿»è­¯
        all_data = translate_titles_to_en(all_data)

        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('data', exist_ok=True)

        # è¼¸å‡º CSV (æ¨™é¡Œå·²é™„åŠ ç¿»è­¯)
        df = pd.DataFrame(all_data)
        df.to_csv(f"data/raw_news_{date_str}.csv", index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ CSV å·²å­˜è‡³: data/raw_news_{date_str}.csv")

        # ç”¢å‡º AI å ±å‘Š
        print(f"\nğŸ¤– å•Ÿå‹• AI ç¸½ç·¨è¼¯æ¨¡å¼ (ä¸‰èªè¼¸å‡º)...")
        ai_report_content = generate_ai_report(all_data)
        with open(f"data/racing_report_{date_str}.md", "w", encoding="utf-8") as f:
            f.write(ai_report_content)
        print(f"âœ¨ AI æˆ°å ±å·²ç”Ÿæˆ: racing_report_{date_str}.md")
    else:
        print("\nâŒ ä»Šæ—¥ç„¡æ–°èæ•¸æ“šã€‚")

if __name__ == "__main__":
    run_all()
