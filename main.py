import pandas as pd
from datetime import datetime
import os
import importlib
import google.generativeai as genai
import time

# --- AI è¨­å®š ---
API_KEY = os.getenv("GEMINI_API_KEY")
if API_KEY:
    genai.configure(api_key=API_KEY)
    # ä½¿ç”¨ gemini-1.5-flashï¼Œè™•ç†é€Ÿåº¦å¿«ä¸”ä¸Šä¸‹æ–‡è¦–çª—å¤§ï¼Œé©åˆè™•ç†æ•´ä»½æ¸…å–®
    model = genai.GenerativeModel('gemini-1.5-flash')
else:
    model = None

def generate_ai_report(all_headlines):
    """å°‡æ‰€æœ‰æ¨™é¡ŒæŠ•çµ¦ AI é€²è¡Œåˆ†é¡ã€æ’åºèˆ‡ç¶œåˆæ‘˜è¦"""
    if not model or not all_headlines:
        return "AI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼šç¼ºå°‘æ•¸æ“šæˆ– API Keyã€‚"

    # å°‡æ‰€æœ‰æ–°èæ•´ç†æˆå¸¶æœ‰ä¾†æºçš„æ¸…å–®
    news_list_text = ""
    for i, item in enumerate(all_headlines):
        news_list_text += f"{i+1}. [{item['source']}] {item['title']}\n"

    # æ§‹é€ çµ¦ AI çš„ç¸½ç·¨è¼¯æŒ‡ä»¤
    prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…¨çƒè³½é¦¬æ–°èç¸½ç·¨è¼¯ã€‚ä»¥ä¸‹æ˜¯ä»Šå¤©å¾è‹±åœ‹ã€é¦™æ¸¯ã€æ¾³æ´²ã€æ—¥æœ¬åŠç¾åœ‹æ”¶é›†åˆ°çš„æœ€æ–°è³½é¦¬æ–°èæ¨™é¡Œæ¸…å–®ï¼š
    
    {news_list_text}
    
    è«‹æ ¹æ“šä»¥ä¸Šå…§å®¹ï¼Œç‚ºæˆ‘æ’°å¯«ä¸€ä»½ã€Œå…¨çƒè³½é¦¬æƒ…å ±æ‘˜è¦ã€ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š
    
    1. **ä»Šæ—¥é ­æ¢ (Top 5 Priority)**ï¼šå¾æ¸…å–®ä¸­æŒ‘é¸å‡ºå…¨çƒæœ€é‡è¦çš„ 5 å‰‡æ–°èï¼Œä¸¦åˆ†åˆ¥ç”¨ä¸€å¥è©±è§£é‡‹å…¶é‡è¦æ€§ã€‚
    2. **åˆ†é¡æ•´ç†**ï¼šå°‡å‰©é¤˜æ–°èæŒ‰ã€Œé¦™æ¸¯é¦¬åœˆå‹•æ…‹ã€ã€ã€Œåœ‹éš›å¤§è³½æƒ…å ±ã€ã€ã€Œåå®¶åˆ†æèˆ‡è²¼å£«ã€ã€ã€Œè‚²é¦¬èˆ‡æ‹è³£å¸‚å ´ã€ç­‰é¡åˆ¥é€²è¡Œæ­¸ç´æ‘˜è¦ã€‚
    3. **å…¨çƒè¶¨å‹¢çŸ­è©•**ï¼šç”¨ç´„ 100 å­—åˆ†æä»Šæ—¥å…¨çƒè³½é¦¬ç•Œçš„æ•´é«”æ°›åœæˆ–å€¼å¾—é—œæ³¨çš„è¶¨å‹¢ã€‚
    4. **è¦æ±‚**ï¼šè«‹å…¨éƒ¨ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€ï¼Œé¢¨æ ¼å°ˆæ¥­ä¸”ç²¾ç…‰ã€‚
    
    è¼¸å‡ºæ ¼å¼è«‹ç›´æ¥ä½¿ç”¨ Markdown èªæ³•ã€‚
    """

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"AI å ±å‘Šç”Ÿæˆå‡ºéŒ¯: {e}"

def run_all():
    all_data = []
    # åŸ·è¡Œæ‰€æœ‰å·²é–‹ç™¼å®Œæˆçš„åª’é«”æ¨¡çµ„
    SITES = [
        'racing_post', 
        'scmp_racing', 
        'singtao_racing', 
        'punters_au', 
        'netkeiba_news', 
        'bloodhorse_news'
    ]
    
    # 1. åŸ·è¡Œçˆ¬èŸ²æŠ“å–
    for site in SITES:
        try:
            print(f"\n>>> æ­£åœ¨æŠ“å–: {site}")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data:
                    item['source'] = site
                all_data.extend(data)
                print(f"    âœ… æˆåŠŸæŠ“å– {len(data)} å‰‡")
        except Exception as e:
            print(f"    âŒ {site} å‡ºéŒ¯: {e}")

    if all_data:
        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('data', exist_ok=True)

        # --- è¼¸å‡ºæ–‡ä»¶ 1ï¼šåŸå§‹æ•¸æ“š Excel (CSV) ---
        df = pd.DataFrame(all_data)
        csv_filename = f"data/raw_news_{date_str}.csv"
        # ä½¿ç”¨ utf-8-sig ç¢ºä¿ Excel é–‹å•Ÿä¸­æ–‡ä¸äº‚ç¢¼
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ åŸå§‹æ•¸æ“šå·²å­˜è‡³: {csv_filename}")

        # --- è¼¸å‡ºæ–‡ä»¶ 2ï¼šAI ç¶œåˆå ±å‘Š (Markdown) ---
        print(f"\nğŸ¤– æ­£åœ¨å•Ÿå‹• AI ç¸½ç·¨è¼¯æ¨¡å¼ï¼Œåˆ†æ {len(all_data)} å‰‡æƒ…å ±...")
        ai_report_content = generate_ai_report(all_data)
        
        md_filename = f"data/racing_report_{date_str}.md"
        with open(md_filename, "w", encoding="utf-8") as f:
            f.write(ai_report_content)
        
        print(f"âœ¨ AI æˆ°æƒ…æ—¥å ±å·²ç”Ÿæˆ: {md_filename}")
        print("\n--- AI æ‘˜è¦é è¦½ ---\n")
        print(ai_report_content[:300] + "...") 
    else:
        print("\nâŒ ä»Šæ—¥æœªæŠ“å–åˆ°ä»»ä½•è³‡æ–™ã€‚")

if __name__ == "__main__":
    run_all()
