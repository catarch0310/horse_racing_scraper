import pandas as pd
from datetime import datetime
import os
import importlib
import google.generativeai as genai
import time

# --- AI æ ¸å¿ƒè¨­å®š (ä¿®æ­£æ¨¡å‹åˆå§‹åŒ–å¤±æ•—å•é¡Œ) ---
API_KEY = os.getenv("GEMINI_API_KEY")

def get_model():
    if not API_KEY:
        print("âŒ æ‰¾ä¸åˆ° API KEY")
        return None
    try:
        genai.configure(api_key=API_KEY)
        # ç›´æ¥ä½¿ç”¨å®˜æ–¹æœ€ç©©å®šçš„åç¨±
        return genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        print(f"âŒ AI é…ç½®å¤±æ•—: {e}")
        return None

# ç›´æ¥åˆå§‹åŒ–ï¼Œä¸è¦åšæª¢æ¸¬è«‹æ±‚
model_instance = get_model()

def generate_ai_report(all_headlines):
    """ ç”Ÿæˆè‹±ã€ä¸­ã€æ—¥ä¸‰èªå ±å‘Š """
    if not model_instance:
        return "AI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼šæ¨¡å‹æœªå°±ç·’ã€‚è«‹æª¢æŸ¥ç’°å¢ƒè®Šæ•¸ GEMINI_API_KEYã€‚"

    news_list_text = ""
    for i, item in enumerate(all_headlines):
        news_list_text += f"{i+1}. [{item['source']}] {item['title']}\n"

    prompt = f"""
    You are a Global Horse Racing Chief Editor. 
    Analyze these headlines from UK, HK, AU, JP, and US:
    
    {news_list_text}
    
    Please generate a report in THREE parts in this exact order:
    1. ENGLISH VERSION
    2. TRADITIONAL CHINESE VERSION (HONG KONG)
    3. JAPANESE VERSION

    Requirements for each language:
    - **Top 5 Priority**: Choose the 5 most important global news and explain why in one sentence.
    - **Categorized Summaries**: Summarize others into "HK Racing", "International Racing", and "Analysis".
    - **Global Trend**: A 100-word analysis of today's atmosphere.

    --- SPECIAL INSTRUCTIONS FOR CHINESE ---
    - Use Traditional Chinese (Hong Kong).
    - **MANDATORY**: Use official Hong Kong Jockey Club (HKJC) translations for names.
    - Examples: 'David Hayes' -> 'å¸Œæ–¯', 'Aidan O'Brien' -> 'å²³ä¼¯ä»', 'Sha Tin' -> 'æ²™ç”°', 'Happy Valley' -> 'è·‘é¦¬åœ°'.

    --- SPECIAL INSTRUCTIONS FOR JAPANESE ---
    - Use professional Japanese horse racing terminology (e.g., é‡è³, è¿½ã„åˆ‡ã‚Š).

    Format with professional Markdown headers.
    """

    try:
        # å¢åŠ è¼¸å‡º token é™åˆ¶ä»¥å®¹ç´ä¸‰ç¨®èªè¨€
        response = model_instance.generate_content(
            prompt, 
            generation_config={"max_output_tokens": 4000, "temperature": 0.7}
        )
        return response.text.strip()
    except Exception as e:
        return f"AI å ±å‘Šå…§å®¹ç”Ÿæˆå‡ºéŒ¯: {str(e)}"

def run_all():
    all_data = []
    # åª’é«”æ¸…å–®
    SITES = ['racing_post', 'scmp_racing', 'singtao_racing', 'punters_au', 'racing_com', 'netkeiba_news', 'bloodhorse_news']
    
    for site in SITES:
        try:
            print(f"\n>>> ä»»å‹™é–‹å§‹: {site}")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data: item['source'] = site
                all_data.extend(data)
                print(f"    âœ… æˆåŠŸæŠ“å– {len(data)} å‰‡")
        except Exception as e:
            print(f"    âŒ {site} éŒ¯èª¤: {e}")

    if all_data:
        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('data', exist_ok=True)

        # 1. åŸå§‹ CSV
        df = pd.DataFrame(all_data)
        df.to_csv(f"data/raw_news_{date_str}.csv", index=False, encoding='utf-8-sig')

        # 2. AI ä¸‰èªå ±å‘Š
        print(f"\nğŸ¤– æ­£åœ¨ç”Ÿæˆè‹±/ä¸­/æ—¥ä¸‰èªæˆ°å ±...")
        report = generate_ai_report(all_data)
        with open(f"data/racing_report_{date_str}.md", "w", encoding="utf-8") as f:
            f.write(report)
        print(f"âœ¨ ä»»å‹™å®Œæˆï¼")
    else:
        print("\nâŒ æœªæŠ“å–åˆ°ä»»ä½•è³‡æ–™ã€‚")

if __name__ == "__main__":
    run_all()
