import pandas as pd
from datetime import datetime
import os
import importlib
import google.generativeai as genai
import time

# --- AI è¨­å®šèˆ‡è‡ªå‹•åµæ¸¬ (å®Œå…¨ä¿ç•™ä½ çš„ç©©å®šé‚è¼¯) ---
API_KEY = os.getenv("GEMINI_API_KEY")

def get_best_model():
    """ è‡ªå‹•åµæ¸¬å¯ç”¨çš„æ¨¡å‹åç¨±ï¼Œè§£æ±º 404 v1beta éŒ¯èª¤ """
    if not API_KEY:
        return None
    
    genai.configure(api_key=API_KEY)
    
    candidate_names = [
        'gemini-1.5-flash', 
        'models/gemini-1.5-flash', 
        'gemini-1.5-pro',
        'models/gemini-1.5-pro'
    ]
    
    print("ğŸ¤– æ­£åœ¨åµæ¸¬å¯ç”¨ AI æ¨¡å‹...")
    for name in candidate_names:
        try:
            model = genai.GenerativeModel(name)
            model.generate_content("hi", generation_config={"max_output_tokens": 1})
            print(f"âœ… æˆåŠŸå•Ÿç”¨æ¨¡å‹: {name}")
            return model
        except Exception:
            continue
    
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"âš ï¸ ä½¿ç”¨ç³»çµ±è‡ªå‹•ç™¼ç¾æ¨¡å‹: {m.name}")
                return genai.GenerativeModel(m.name)
    except:
        pass
        
    return None

# åˆå§‹åŒ–æ¨¡å‹
model_instance = get_best_model()

def generate_ai_report(all_headlines):
    """å¼·åŒ–ç‰ˆ AI ç¸½ç·¨è¼¯å ±å‘Šç”Ÿæˆï¼šçµæ§‹æ›´å°ˆæ¥­ã€åˆ†ææ›´é€å¾¹"""
    if not model_instance:
        return "AI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼šæ¨¡å‹åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ API Key æˆ–æ¨¡å‹æ¬Šé™ã€‚"

    # æ•´ç†æ¨™é¡Œæ¸…å–®ï¼ŒåŠ å…¥ ID æ–¹ä¾¿ AI æ¯”å°
    news_list_text = ""
    for i, item in enumerate(all_headlines):
        news_list_text += f"ID: {i+1} | Source: {item['source']} | Title: {item['title']}\n"

    # --- æ”¹é€ å¾Œçš„å°ˆæ¥­ç·¨è¼¯ Prompt ---
    prompt = f"""
    # Role
    You are the Executive Chief Editor of a global premium horse racing news agency. Analyze the following headlines from UK, HK, AU, JP, US, and FRANCE:
    
    {news_list_text}
    
    # Task
    Generate a "Global Racing Strategic Intelligence Report" in THREE languages: 1. ENGLISH, 2. TRADITIONAL CHINESE (HK), 3. JAPANESE.

    # Format & Structure (Apply to EACH language version)
    
    ## 1. Top 5 Priority News (Breaking & Strategic)
    - Identify the 5 most critical stories globally.
    - Instead of just summarizing, explain their **Strategic Impact** (e.g., "This injury changes the G1 field hierarchy" or "The auction results indicate a strong market for Japanese bloodlines").

    ## 2. Regional Intelligence Matrix (Desk Summaries)
    Group and summarize the remaining news into these professional desks:
    - **Hong Kong Desk**: Local trainer/jockey moves, betting sentiment, and race updates.
    - **Oceania Desk (AU/NZ)**: Sales (Inglis/Magic Millions), industry politics, and carnival previews.
    - **Japan & Asian-Pacific Desk**: JRA updates, Japanese raiders abroad, and key workouts.
    - **EMEA & Americas Desk**: US Triple Crown preps, UK/France major stakes, and breeding news.

    ## 3. The "Global Pulse" (Cross-Border Connections)
    - A 100-word expert analysis identifying trends connecting different regions (e.g., European jockeys riding in Australia, or the impact of global currency on bloodstock sales).

    ## 4. Editor's Watchlist
    - 3 key events or horses to track in the next 48 hours.

    # Mandatory Terminology & Translation Instructions
    - **Traditional Chinese (Hong Kong)**: MUST follow official Hong Kong Jockey Club (HKJC) translations.
        - Names: David Hayes -> å¸Œæ–¯, James McDonald -> éº¥é“æœ—, Zac Purton -> æ½˜é “, Ryan Moore -> è«é›…, Aidan O'Brien -> å²³ä¼¯ä».
        - Races/Places: Sha Tin -> æ²™ç”°, Classic Mile -> ç¶“å…¸ä¸€å“©è³½, G1 -> ä¸€ç´šè³½, Bloodstock -> è¡€çµ±/è‚²é¦¬.
    - **Japanese**: Use professional terminology (é‡è³, è¿½ã„åˆ‡ã‚Š, ãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¦ãƒˆ, ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°).

    # Style
    - Authoritative, concise, and structured with professional Markdown headers and bullet points.
    """

    try:
        # ä¿®æ­£ï¼šåŠ å…¥å®‰å…¨è¨­å®šé˜²æ­¢ã€Œè³­åšç›¸é—œå…§å®¹ã€éæ¿¾ï¼Œä¸¦å¢åŠ è¼¸å‡ºé•·åº¦
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        response = model_instance.generate_content(
            prompt,
            generation_config={
                "max_output_tokens": 8000, # å¢åŠ é•·åº¦ç¢ºä¿ä¸‰èªä¸è¢«åˆ‡æ–·
                "temperature": 0.4,       # é™ä½éš¨æ©Ÿæ€§ï¼Œç¢ºä¿è­¯åç²¾ç¢ºç©©å®š
            },
            safety_settings=safety_settings
        )
        return response.text.strip()
    except Exception as e:
        return f"AI å ±å‘Šå…§å®¹ç”Ÿæˆå‡ºéŒ¯: {str(e)}"

def run_all():
    all_data = []
    # åª’é«”æ¸…å–®
    SITES = ['racing_post', 'scmp_racing', 'singtao_racing', 'punters_au', 'racing_com', 'tospo_keiba', 'netkeiba_news', 'bloodhorse_news', 'the_straight', 'anz_bloodstock', 'ttr_ausnz', 'smh_racing', 'drf_news', 'racenet_news', 'daily_telegraph', 'equidia_racing']
    
    # 1. åŸ·è¡Œçˆ¬èŸ²
    for site in SITES:
        try:
            print(f"\n>>> ä»»å‹™é–‹å§‹: {site}")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data: item['source'] = site
                all_data.extend(data)
                print(f"    âœ… æŠ“åˆ° {len(data)} å‰‡")
        except Exception as e:
            print(f"    âŒ {site} éŒ¯èª¤: {e}")

    if all_data:
        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('data', exist_ok=True)

        # --- è¼¸å‡ºæ–‡ä»¶ 1ï¼šCSV ---
        df = pd.DataFrame(all_data)
        csv_filename = f"data/raw_news_{date_str}.csv"
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ CSV å·²å­˜è‡³: {csv_filename}")

        # --- è¼¸å‡ºæ–‡ä»¶ 2ï¼šAI Markdown ---
        print(f"\nğŸ¤– å•Ÿå‹• AI ç¸½ç·¨è¼¯æ¨¡å¼ (ä¸‰èª/å°ˆæ¥­çµæ§‹)...")
        ai_report_content = generate_ai_report(all_data)
        
        md_filename = f"data/racing_report_{date_str}.md"
        with open(md_filename, "w", encoding="utf-8") as f:
            f.write(ai_report_content)
        
        print(f"âœ¨ AI æˆ°å ±å·²ç”Ÿæˆ: {md_filename}")
    else:
        print("\nâŒ ä»Šæ—¥ç„¡æ–°èæ•¸æ“šï¼Œä¸ç”Ÿæˆå ±å‘Šã€‚")

if __name__ == "__main__":
    run_all()
