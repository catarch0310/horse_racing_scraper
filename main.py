import pandas as pd
from datetime import datetime
import os
import importlib
import google.generativeai as genai
import time
from difflib import SequenceMatcher

# --- 1. AI æ ¸å¿ƒè¨­å®šèˆ‡è‡ªå‹•ä¿®å¾©åµæ¸¬ ---
API_KEY = os.getenv("GEMINI_API_KEY")

def get_best_model():
    """ 
    æ”¹è‰¯ç‰ˆåµæ¸¬ï¼šç¢ºä¿ä¸æœƒå›å‚³ None
    è§£æ±º 'AI Model Not Ready' èˆ‡ '404 v1beta' å ±éŒ¯
    """
    if not API_KEY:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        return None
    
    genai.configure(api_key=API_KEY)
    
    # æŒ‰ç…§ç©©å®šåº¦æ’åºçš„å€™é¸åå–®
    candidate_names = [
        'gemini-1.5-flash', 
        'models/gemini-1.5-flash', 
        'gemini-1.5-pro',
        'models/gemini-1.5-pro'
    ]
    
    print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ– AI æ¨¡å‹...")
    for name in candidate_names:
        try:
            model = genai.GenerativeModel(name)
            # è¼•é‡æ¸¬è©¦ï¼šç¢ºèªæ¨¡å‹æ˜¯å¦å¯ç”¨
            model.generate_content("hi", generation_config={"max_output_tokens": 1})
            print(f"âœ… æˆåŠŸå•Ÿç”¨æ¨¡å‹: {name}")
            return model
        except Exception as e:
            # print(f"   â„¹ï¸ è·³éæ¨¡å‹ {name}: {str(e)[:50]}")
            continue
    
    # æœ€çµ‚å‚™æ´ï¼šå¼·è¡ŒæŒ‡å®šï¼Œä¸é€²è¡Œé æ¸¬è©¦
    print("âš ï¸ é æ¸¬è©¦å¤±æ•—ï¼Œå¼·è¡Œæ›è¼‰ gemini-1.5-flash...")
    return genai.GenerativeModel('gemini-1.5-flash')

# ç¢ºä¿æ¨¡å‹å¯¦ä¾‹è¢«å‰µå»º
model_instance = get_best_model()

# --- 2. æ¨™é¡Œç¿»è­¯åŠŸèƒ½ ---
def translate_titles_to_en(all_data):
    """ å°‡æ¨™é¡Œè‹±è­¯ä¸¦é™„åœ¨å¾Œæ–¹ï¼Œç¢ºä¿æ•¸æ“šä¸äº‚æ‰ """
    if not model_instance or not all_data: 
        print("âš ï¸ AI æœªå°±ç·’ï¼Œè·³éç¿»è­¯æ­¥é©Ÿ")
        return all_data
    
    print(f"ğŸŒ æ­£åœ¨ç¿»è­¯ {len(all_data)} å‰‡æ¨™é¡Œ...")
    raw_titles = [item['title'] for item in all_data]
    
    # æŒ‡ä»¤å„ªåŒ–ï¼šç¢ºä¿ AI ä¹–ä¹–é€è¡Œç¿»è­¯
    prompt = "Translate these racing headlines into English. ONLY English, one per line, no extra text. If it is already English, leave it:\n\n" + "\n".join(raw_titles)
    
    try:
        response = model_instance.generate_content(prompt)
        translated_lines = response.text.strip().split('\n')
        
        # æ•¸é‡ä¸€è‡´æ‰é€²è¡Œåˆä½µ
        if len(translated_lines) == len(all_data):
            for i in range(len(all_data)):
                orig = all_data[i]['title']
                en = translated_lines[i].strip()
                if orig.lower() != en.lower():
                    all_data[i]['title'] = f"{orig} ({en})"
            print("âœ… æ¨™é¡Œè‹±è­¯é™„åŠ æˆåŠŸ")
        else:
            print(f"âš ï¸ ç¿»è­¯æ•¸é‡å°ä½å¤±æ•— ({len(translated_lines)}/{len(all_data)})")
    except Exception as e:
        print(f"âš ï¸ ç¿»è­¯éç¨‹å ±éŒ¯: {e}")
    
    return all_data

# --- 3. æˆ°ç•¥å‹åˆ†æå ±å‘Š (è‹±æ–‡ç‰ˆ) ---
def generate_strategic_report(all_headlines):
    """
    åˆ†ææ•¸æ“šï¼šTop 5 Keywords + 2-3 Outliers (é‡å°è³‡æ·±ç·¨è¼¯)
    """
    if not model_instance: return "AI Model Not Ready."

    news_list_text = ""
    for i, item in enumerate(all_headlines):
        news_list_text += f"ID: {i+1} | Source: {item['source']} | Title: {item['title']}\n"

    prompt = f"""
    # Role
    You are a Strategic Industry Analyst for global horse racing. 
    Review the following raw data and produce a professional brief for senior editors.

    # Input Data
    {news_list_text}

    # Task (Output in ENGLISH only)
    1. **TOP 5 STRATEGIC KEYWORDS/THEMES**: 
       Identify 5 keywords/themes that dominate today's global headlines. Explain why they are trending (e.g., specific auction results, key stallion performance, or major race prep).

    2. **OUTLIER RADAR (2-3 Anomalies)**:
       Identify 2-3 headlines that are "unusual," "niche," or "out-of-the-ordinary." These stories may represent hidden industry shifts or unique local incidents worth deeper investigation. Explain why an editor should look closer.

    # Tone
    Analytical, professional, and concise. No fluff. Use Markdown.
    """

    try:
        # é—œé–‰å®‰å…¨é™åˆ¶ï¼Œé˜²æ­¢è³½é¦¬ç›¸é—œè©å½™è¢«èª¤å°
        safety = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        response = model_instance.generate_content(
            prompt, 
            generation_config={"temperature": 0.3},
            safety_settings=safety
        )
        return response.text.strip()
    except Exception as e:
        return f"Report generation failed: {str(e)}"

# --- 4. è³‡æ–™æ¸…æ´— ---
def similarity(a, b):
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()

def deduplicate_data(all_data):
    if not all_data: return []
    unique_url_data = []
    seen_urls = set()
    for item in all_data:
        if item['link'] not in seen_urls:
            seen_urls.add(item['link'])
            unique_url_data.append(item)
    
    final_data = []
    for item in unique_url_data:
        is_duplicate = False
        for existing_item in final_data:
            if similarity(item['title'], existing_item['title']) > 0.85:
                is_duplicate = True
                break
        if not is_duplicate:
            final_data.append(item)
    return final_data

# --- 5. ä¸»åŸ·è¡Œæµç¨‹ ---
def run_all():
    all_data = []
    SITES = ['racing_post', 'scmp_racing', 'singtao_racing', 'punters_au', 'racing_com', 'tospo_keiba', 'netkeiba_news', 'bloodhorse_news', 'the_straight', 'anz_bloodstock', 'ttr_ausnz', 'smh_racing', 'drf_news', 'racenet_news', 'daily_telegraph', 'equidia_racing']
    
    for site in SITES:
        try:
            print(f"\n>>> Task: {site}")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data: item['source'] = site
                all_data.extend(data)
                print(f"    âœ… Captured {len(data)} items")
        except Exception as e:
            print(f"    âŒ {site} Error: {e}")

    if all_data:
        # A. æ•¸æ“šæ¸…æ´—
        all_data = deduplicate_data(all_data)
        
        # B. ç¿»è­¯æ¨™é¡Œ (å­˜å…¥ CSV å‰å®Œæˆ)
        all_data = translate_titles_to_en(all_data)

        date_str = datetime.now().strftime('%Y%m%d')
        os.makedirs('data', exist_ok=True)

        # C. å„²å­˜åŸå§‹ CSV
        df = pd.DataFrame(all_data)
        csv_filename = f"data/raw_news_{date_str}.csv"
        df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ CSV saved: {csv_filename}")

        # D. ç”Ÿæˆæˆ°ç•¥å ±å‘Š
        print(f"\nğŸ¤– Generating Strategic Report...")
        ai_report = generate_strategic_report(all_data)
        
        md_filename = f"data/strategic_report_{date_str}.md"
        with open(md_filename, "w", encoding="utf-8") as f:
            f.write(ai_report)
        print(f"âœ¨ Strategic Report saved: {md_filename}")
    else:
        print("\nâŒ No data collected today.")

if __name__ == "__main__":
    run_all()
