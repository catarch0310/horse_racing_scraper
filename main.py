import pandas as pd
from datetime import datetime
import os
import importlib
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import time

# --- AI è¨­å®š ---
API_KEY = os.getenv("GEMINI_API_KEY")
if API_KEY:
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('models/gemini-1.5-flash')
else:
    model = None

def generate_summary_with_retry(title, content, retries=3):
    """å…·å‚™è‡ªå‹•é‡è©¦åŠŸèƒ½çš„æ‘˜è¦ç”¢ç”Ÿå™¨"""
    if not model: return "æœªè¨­å®š API KEY"
    
    prompt = f"è«‹ç”¨ç¹é«”ä¸­æ–‡å°‡ä»¥ä¸‹è³½é¦¬æ–°èç¸®çŸ­ç‚ºä¸€å¥ç´„ 50 å­—çš„æ™ºèƒ½æ‘˜è¦ï¼š\n\næ¨™é¡Œï¼š{title}\nå…§å®¹ï¼š{content[:2000]}"
    
    for i in range(retries):
        try:
            response = model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            err_msg = str(e)
            if "429" in err_msg:
                print(f"      âš ï¸ è§¸ç™¼é »ç‡é™åˆ¶ï¼Œç­‰å¾… 15 ç§’å¾Œé‡è©¦ ({i+1}/{retries})...")
                time.sleep(15) # é‡åˆ° 429 ç­‰ä¹…ä¸€é»
            else:
                return f"æ‘˜è¦å¤±æ•—: {err_msg}"
    return "æ‘˜è¦å¤±æ•—: å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ (429)"

def get_full_text(url, source):
    if source == 'on_cc_racing': return ""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, 'html.parser')
        paragraphs = soup.find_all('p')
        return "\n".join([p.get_text() for p in paragraphs if len(p.get_text()) > 25])[:2500]
    except:
        return ""

def run_all():
    all_data = []
    # ç¢ºä¿ punters_au åœ¨æ¸…å–®ä¸­
    SITES = ['racing_post', 'scmp_racing', 'on_cc_racing', 'punters_au']
    
    for site in SITES:
        try:
            print(f"\n>>> çˆ¬å– {site}...")
            module = importlib.import_module(f"scrapers.{site}")
            data = module.scrape()
            if data:
                for item in data: item['source'] = site
                all_data.extend(data)
                print(f"    âœ… æŠ“åˆ° {len(data)} å‰‡")
        except Exception as e:
            print(f"    âŒ {site} éŒ¯èª¤: {e}")

    if all_data:
        total = len(all_data)
        print(f"\nğŸ¤– é€²è¡Œ AI æ‘˜è¦ (ç¸½å…± {total} å‰‡)...")
        results = []
        for i, item in enumerate(all_data):
            print(f"    ({i+1}/{total}) è™•ç†: {item['title'][:20]}...")
            
            # å–å¾—å…§æ–‡ä¸¦æ‘˜è¦
            text = get_full_text(item['link'], item['source'])
            item['ai_summary'] = generate_summary_with_retry(item['title'], text)
            results.append(item)
            
            # åŸºç¤å»¶é²ï¼šå…è²»ç‰ˆé™åˆ¶ 15RPMï¼Œæ¯å‰‡è‡³å°‘è¦é–“éš” 4.5 ç§’
            time.sleep(4.5)

        df = pd.DataFrame(results)
        os.makedirs('data', exist_ok=True)
        filename = f"data/ai_racing_report_{datetime.now().strftime('%Y%m%d')}.csv"
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ¨ å­˜æª”æˆåŠŸ: {filename}")

if __name__ == "__main__":
    run_all()
